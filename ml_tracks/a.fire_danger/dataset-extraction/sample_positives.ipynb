{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from shapely import wkt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ADD the path to the burned areas file\n",
    "gdf = gpd.read_file(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ADD the path to the datacube\n",
    "ds = xr.open_zarr(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ADD the path to the biomes\n",
    "biome = gpd.read_file(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biome=biome[(biome['BIOME_NUM']== 12.0) & (biome['REALM']=='Palearctic')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare geopandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change the CRS of gdf to EPSG:4326\n",
    "# slice gdf to rows with IGNITION_D >= '2002-04-01'\n",
    "gdf = gdf[gdf['IGNITION_D'] >= '2006-04-02'].reset_index(drop=True)\n",
    "gdf = gdf[gdf['IGNITION_D'] <= '2022-09-30'].reset_index(drop=True)\n",
    "gdf = gdf[gdf['AREA_HA'].astype(float) >= 30]\n",
    "# convert FIREDATE column to datetime\n",
    "gdf['IGNITION_D'] = pd.to_datetime(gdf['IGNITION_D'])\n",
    "# subtract 1 day from FIREDATE\n",
    "gdf['IGNITION_D'] = gdf['IGNITION_D'] - pd.Timedelta(days=1)\n",
    "# get the year of FIREDATE\n",
    "gdf['IGNITION_YEAR'] = gdf['IGNITION_D'].dt.year\n",
    "# change geometry\n",
    "gdf['geometry_h'] = gdf['geometry_h'].apply(wkt.loads)\n",
    "gdf = gdf.set_geometry('geometry_h')\n",
    "gdf.crs = \"EPSG:5643\"\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.sjoin(gdf, biome, how = 'inner', predicate = 'intersects').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the save directories\n",
    "save_dir = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lag = 30\n",
    "patch_size = 125\n",
    "patch_half = 125//2\n",
    "len_x = len(ds['x'])\n",
    "len_y = len(ds['y'])\n",
    "\n",
    "s_cl = 0\n",
    "s_seg = 0\n",
    "for i in tqdm(range(len(gdf))):\n",
    "    np_var = {}\n",
    "    date_format = '%Y-%m-%d'\n",
    "    ignition_date = gdf.loc[i, 'IGNITION_D']\n",
    "    ignition_xy = gdf.loc[i, 'geometry_h']\n",
    "              \n",
    "    ign_date_str  = (ignition_date).strftime('%Y-%m-%d')\n",
    "    ign_date_lag_str = (ignition_date - pd.Timedelta(days=lag-1)).strftime('%Y-%m-%d')\n",
    "              \n",
    "    pos_sample_ds = ds.sel(time=slice(ign_date_lag_str, ign_date_str))\n",
    "    \n",
    "    pos_sample = pos_sample_ds.sel(x=ignition_xy.x, y=ignition_xy.y, method='nearest')\n",
    "    x_idx = np.where(pos_sample_ds['x']==pos_sample['x'].values)[0].item()\n",
    "    y_idx = np.where(pos_sample_ds['y']==pos_sample['y'].values)[0].item()\n",
    "    \n",
    "    if ((x_idx - patch_half < 0) or (x_idx + patch_half + 1 >= len_x) or (y_idx - patch_half < 0) or (y_idx + patch_half + 1 >= len_y)):\n",
    "        print('border')\n",
    "        continue\n",
    "        \n",
    "    pos_sample_ds = pos_sample_ds.isel(x=slice(x_idx - patch_half,x_idx + patch_half + 1),\n",
    "                                      y=slice(y_idx - patch_half,y_idx + patch_half + 1))\n",
    "    \n",
    "    pos_sample_ds_vars = list(pos_sample_ds.keys()) \n",
    "    year = str(pos_sample_ds.time.dt.year.values[-1])\n",
    "    for var in pos_sample_ds_vars:\n",
    "        if var == 'population' or 'lc' in var:\n",
    "            del pos_sample_ds[var]\n",
    "            if year == '2006':\n",
    "                pos_sample_ds[var] = ds[var].sel(time=slice('2006-04-01', '2006-04-01'))[0].isel(x=slice(x_idx - patch_half,x_idx + patch_half + 1),\n",
    "                                      y=slice(y_idx - patch_half,y_idx + patch_half + 1)) \n",
    "            else:\n",
    "                dt = str(year) + '-01-01'\n",
    "                pos_sample_ds[var] = ds[var].sel(time=slice(dt, dt))[0].isel(x=slice(x_idx - patch_half,x_idx + patch_half + 1),\n",
    "                                      y=slice(y_idx - patch_half,y_idx + patch_half + 1))\n",
    "                \n",
    "    del pos_sample_ds['spatial_ref']\n",
    "    pos_sample_ds = pos_sample_ds.load()\n",
    "    \n",
    "\n",
    "    pos_sample_ds = pos_sample_ds.isel(x=patch_half, y=patch_half)\n",
    "    pos_sample_ds = pos_sample_ds.load()\n",
    "    pos_sample_ds['burned_area_has'] = float(gdf.loc[i, 'AREA_HA'])\n",
    "    if pd.notnull(pos_sample_ds['t2m'][0]): \n",
    "        if s_cl == 0: \n",
    "            df = pos_sample_ds.to_dataframe()\n",
    "            df['time_idx'] = np.arange(0,lag)\n",
    "            df['sample'] = s_cl\n",
    "        else:\n",
    "            df1 = pos_sample_ds.to_dataframe()\n",
    "            df1['time_idx'] = np.arange(0,lag)\n",
    "            df1['sample'] = s_cl\n",
    "            df = pd.concat([df, df1], axis=0)\n",
    "            del df1\n",
    "        s_cl+=1\n",
    "    del pos_sample_ds\n",
    "    gc.collect()\n",
    "path_df = save_dir / 'positives.csv'\n",
    "df.to_csv(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e777a3fa5c7295abfc04ae8075218d3d543836079b2092325f3aac9db08acff8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
